人工智能（Artificial Intelligence，简称AI）是计算机科学的一个分支，致力于创建能够模拟人类智能行为的系统。人工智能的研究始于20世纪50年代，由Alan Turing、John McCarthy等先驱奠定了理论基础。

机器学习是人工智能的核心子领域之一。机器学习使计算机能够从数据中自动学习和改进，而无需显式编程。常见的机器学习方法包括监督学习、无监督学习和强化学习。监督学习通过标注数据训练模型，用于分类和回归任务；无监督学习在没有标签的数据中发现隐藏模式，如聚类和降维；强化学习通过与环境交互获得奖励信号来优化策略。

深度学习是机器学习的一个重要分支，使用多层神经网络来学习数据的层次化表示。卷积神经网络（CNN）在图像识别领域取得了突破性进展，循环神经网络（RNN）及其变体LSTM和GRU在序列数据处理方面表现出色。Transformer架构的出现彻底改变了自然语言处理领域，BERT、GPT等预训练语言模型展示了强大的语言理解和生成能力。

自然语言处理（NLP）是人工智能中研究计算机与人类语言交互的领域。NLP的核心任务包括文本分类、命名实体识别、情感分析、机器翻译、问答系统和文本摘要等。近年来，大语言模型（LLM）如GPT-4、Claude、LLaMA等的出现，使得NLP技术取得了质的飞跃。这些模型通过在海量文本数据上进行预训练，获得了强大的语言理解和推理能力。

检索增强生成（Retrieval-Augmented Generation，RAG）是一种结合信息检索和文本生成的技术框架。RAG系统首先从知识库中检索与用户查询相关的文档片段，然后将这些片段作为上下文提供给语言模型，以生成更准确、更有依据的回答。RAG技术有效解决了大语言模型的"幻觉"问题，即模型生成看似合理但实际错误的信息。

向量数据库是RAG系统的关键组件之一。向量数据库专门用于存储和检索高维向量数据。常见的向量数据库包括Chroma、Milvus、Pinecone、Weaviate和Qdrant等。这些数据库支持高效的相似度搜索，能够在毫秒级别内从数百万条向量中找到最相似的结果。向量数据库通常使用近似最近邻（ANN）算法，如HNSW、IVF等，来加速搜索过程。

文本嵌入（Text Embedding）是将文本转换为数值向量的过程。高质量的嵌入模型能够捕捉文本的语义信息，使得语义相似的文本在向量空间中距离较近。常用的嵌入模型包括OpenAI的text-embedding-ada-002、Sentence-BERT、BGE等。嵌入向量的维度通常在384到1536之间，维度越高通常能捕捉更丰富的语义信息，但也会增加存储和计算成本。

文本分片（Chunking）是RAG系统中的重要预处理步骤。合理的分片策略直接影响检索质量和最终回答的准确性。常见的分片策略包括：按固定字符数分片、按段落分片、按语义相似度分片、按递归字符分片等。每种策略都有其优缺点：固定字符分片简单但可能破坏语义完整性；段落分片保留了作者的原始结构但片段大小不均匀；语义分片能产生语义连贯的片段但计算成本较高；递归字符分片在多个层次上寻找自然分割点，是目前最常用的策略。
